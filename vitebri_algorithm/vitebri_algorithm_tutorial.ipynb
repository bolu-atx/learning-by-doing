{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbri Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a village where all villagers are either healthy or have a fever and only the village doctor can determine whether each has a fever. The doctor diagnoses fever by asking patients how they feel. The villagers may only answer that they feel normal, dizzy, or cold.\n",
    "\n",
    "The doctor believes that the health condition of his patients operate as a discrete Markov chain. There are two states, \"Healthy\" and \"Fever\", but the doctor cannot observe them directly; they are hidden from him. On each day, there is a certain chance that the patient will tell the doctor he/she is \"normal\", \"cold\", or \"dizzy\", depending on her health condition.\n",
    "\n",
    "The observations (normal, cold, dizzy) along with a hidden state (healthy, fever) form a hidden Markov model (HMM), and can be represented as follows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"An_example_of_HMM.png\" Alt=\"HMM graphical model\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs = ('normal', 'cold', 'dizzy','dizzy','dizzy')\n",
    "states = ('Healthy', 'Fever')\n",
    "start_p = {'Healthy': 0.6, 'Fever': 0.4}\n",
    "trans_p = {\n",
    "   'Healthy' : {'Healthy': 0.7, 'Fever': 0.3},\n",
    "   'Fever' : {'Healthy': 0.4, 'Fever': 0.6}\n",
    "   }\n",
    "\n",
    "emit_p = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The patient visits three days in a row and the doctor discovers that:\n",
    "\n",
    "* on the first day she feels normal,\n",
    "* on the second day she feels cold,\n",
    "* on the third day she feels dizzy.\n",
    "\n",
    "The doctor has a question: \n",
    "**what is the most likely sequence of health conditions of the patient that would explain these observations?**\n",
    "\n",
    "This is answered by the Viterbi algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Pseudo-Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"vitebri_algorithm_code.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    V = [{}]\n",
    "    for st in states:\n",
    "        # initialize at the starting probability\n",
    "        V[0][st] = {\"prob\": start_p[st] * emit_p[st][obs[0]], \"prev\": None}\n",
    "    \n",
    "    # iterate through each observation\n",
    "    for t in range(1, len(obs)):\n",
    "        # V stores the state history\n",
    "        V.append({})\n",
    "        # for each state\n",
    "        for st in states:\n",
    "            #find the maximum transition probability\n",
    "            # maximum transition probability of the current state=\n",
    "            # the prior probability of being in the previous state * the transition probability of the prior state to the current state\n",
    "            max_tr_prob = max(V[t-1][prev_st][\"prob\"]*trans_p[prev_st][st] for prev_st in states)\n",
    "            \n",
    "            for prev_st in states:\n",
    "                if V[t-1][prev_st][\"prob\"] * trans_p[prev_st][st] == max_tr_prob:\n",
    "                    # find the most likely previous state\n",
    "                    max_prob = max_tr_prob * emit_p[st][obs[t]]\n",
    "                    V[t][st] = {\"prob\": max_prob, \"prev\": prev_st}\n",
    "                    break\n",
    "    for line in dptable(V):\n",
    "         print line\n",
    "    opt = []\n",
    "    # The highest probability\n",
    "    max_prob = max(value[\"prob\"] for value in V[-1].values())\n",
    "    previous = None\n",
    "    # Get most probable state and its backtrack\n",
    "    for st, data in V[-1].items():\n",
    "        if data[\"prob\"] == max_prob:\n",
    "            opt.append(st)\n",
    "            previous = st\n",
    "            break\n",
    "    # Follow the backtrack till the first observation\n",
    "    for t in range(len(V) - 2, -1, -1):\n",
    "        opt.insert(0, V[t + 1][previous][\"prev\"])\n",
    "        previous = V[t + 1][previous][\"prev\"]\n",
    "    print 'The steps of states are ' + ' '.join(opt) + ' with highest probability of %s' % max_prob\n",
    "\n",
    "def dptable(V):\n",
    "     # Print a table of steps from dictionary\n",
    "    yield \" \".join((\"%10d\" % i) for i in range(len(V)))\n",
    "    for state in V[0]:\n",
    "        yield \"%.7s: \" % state + \" \".join(\"%.7s\" % (\"%.7f\" % v[state][\"prob\"]) for v in V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0          1          2          3          4\n",
      "Healthy: 0.30000 0.08400 0.00588 0.00060 0.00021\n",
      "Fever: 0.04000 0.02700 0.01512 0.00544 0.00195\n",
      "The steps of states are Healthy Healthy Fever Fever Fever with highest probability of 0.001959552\n"
     ]
    }
   ],
   "source": [
    "viterbi(obs,states,start_p, trans_p,emit_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "Suppose we are given a hidden Markov model (HMM) with state space $S$, initial probabilities $\\pi _{i}$ of being in state $i$ and transition probabilities $a_{i,j}$ of transitioning from state $i$ to state $j$. Say we observe outputs $y_{1},\\dots ,y_{T}$. The most likely state sequence $x_{1},\\dots ,x_{T}$ that produces the observations is given by the recurrence relations:\n",
    "$${\\begin{array}{rcl}V_{1,k}&=&\\mathrm {P} {\\big (}y_{1}\\ |\\ k{\\big )}\\cdot \\pi _{k}\\\\V_{t,k}&=&\\max _{x\\in S}\\left(\\mathrm {P} {\\big (}y_{t}\\ |\\ k{\\big )}\\cdot a_{x,k}\\cdot V_{t-1,x}\\right)\\end{array}}$$\n",
    "\n",
    "Here $V_{t,k}$ is the probability of the most probable state sequence $\\mathrm {P} {\\big (}x_{1},\\dots ,x_{T},y_{1},\\dots ,y_{T}{\\big )}$ responsible for the first $t$ observations that have $k$ as its final state. The Viterbi path can be retrieved by saving back pointers that remember which state $x$ was used in the second equation. Let $\\mathrm {Ptr} (k,t)$ be the function that returns the value of $x$ used to compute $V_{t,k}$ if $t>1$, or $k$ if $t=1$. Then:\n",
    "\n",
    "\\begin{array}{rcl}x_{T}&=&\\arg \\max _{x\\in S}(V_{T,x})\\\\x_{t-1}&=&\\mathrm {Ptr} (x_{t},t)\\end{array}\n",
    "\n",
    "Here we're using the standard definition of arg max.\n",
    "The complexity of this algorithm is $O(T\\times \\left|{S}\\right|^{2})$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
